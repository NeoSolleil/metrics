
# Transformerのencoder部分から出力されるベクトルを使用して文を評価できないのだろうか？(自動評価タスクにに使用できないか？)


  気になっていたことを試してみたのですが、どこにも見せる場がないので、ここに記そうと思います。
#

## なぜやろうと思ったのか
　　デファクト・スタンダードの自動評価法BLEUは表層的なn-gram一致率に基づいているため意味的な情報が反映されない
![image](https://github.com/NeoSolleil/metrics/assets/126864523/5b729c2c-007d-4553-b54c-2983ae8dae89)

## トランスフォーマーとは  
  トランスフォーマーとは、機械学習の分野で特に自然言語処理のタスクにおいて非常に成功したモデルの一つです。このモデルは、Attention（注意機構）メカニズムを導入し、シーケンス間の依存関係をモデル化するために設計されています。トランスフォーマーは、Googleによって提案され、2017年に"Attention is All You Need"という論文で初めて発表されました。
  
