
# Transformerのencoder部分から出力されるベクトルを使用して文を評価できないのだろうか？(自動評価タスクに使用できないか？)


  今まで気になっていたことを色々試してみたのですが、どこにも見せる場がないので、ここに記そうと思います。  
詳しくはQiitaに書きました
#
# 


## 以下はコードの説明です。

## melt_japan.py

このコードは、参照訳に存在しないMT訳中の単語を検索し、その単語について参照訳中の全単語との類似度を単語分散表現モデルのfastTextを用いて取得し、最も類似度の高い参照訳中の単語とMT訳中の単語を置換することで文を新たに作成するというコードになっています。  


17行目の model_path = ".../fasttext_PATH"#fasttextのモデルへのパス  
の部分にfasttextのモデルへのパスを設定してください

22行目の with open('.../ref_PATH', 'r') as f:#参照訳へのパス  
の部分に参照訳へのパスを設定してください

39行目の with open('.../MT_PATH', 'r') as f:#MT訳へのパス  
の部分にMT訳へのパスを設定してください


## filekakikomi.py

このコードはmelt_japan.pyで新たに文を作成したときに作成した文を学習データに追加させるためのコードです。

４行目の　with open('書き込みたいファイルへのパス', 'r') as f:#書き込みたいファイル
の部分に新たに作成したファイルを設定します

７行目の　with open('書き込まれるフェイルへのパス', mode='a') as f:#書き込まれるふぁいる
の部分には４行目でせってしたフェイルをどこのファイルに追加するのか設定します

